# -*- coding: utf-8 -*-
"""animal_classification_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YJO4MyS5p85S_bIiaCv68aaWqi9XquOW
"""

! pip install -q kaggle
from google.colab import files
files.upload()
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download alessiocorrado99/animals10
! unzip /content/animals10.zip -d data

import cv2
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import pathlib
import glob
from sklearn.metrics import confusion_matrix
import plotly.graph_objects as go
import plotly.express as px
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.model_selection import train_test_split

data_dir = "/content/data/raw-img"
data_dir = pathlib.Path(data_dir)

images = glob.glob('/content/data/raw-img/*/*.jpeg')
print("Total Number of Images", len(images))
images_df = pd.Series(images)

complete_df = pd.DataFrame()

complete_df['file_name'] = images_df

complete_df['class_name'] = images_df.map(lambda ImageName :ImageName.split("/")[-2])

complete_df.head()

complete_df['class_name'].value_counts()

fig = px.bar(complete_df['class_name'].value_counts().head(10),
             x=complete_df['class_name'].value_counts().head(10).index,
             y=complete_df['class_name'].value_counts().head(10).values)

fig.update_layout(title='Raw Data Distribution',
                  xaxis_title='Class Name',
                  yaxis_title='Count',
                  font_size=15, title_x=0.5)

fig.show()

import plotly.express as px

partial_df = complete_df.groupby('class_name').apply(lambda x: x.sample(500)).reset_index(drop=True)

fig = px.bar(partial_df['class_name'].value_counts().head(10),
             x=partial_df['class_name'].value_counts().head(10).index,
             y=partial_df['class_name'].value_counts().head(10).values)

fig.update_layout(title='Processed Data Distribution',
                  xaxis_title='Class Name',
                  yaxis_title='Count',
                  font_size=15, title_x=0.5)

fig.show()

train, test = train_test_split(complete_df, test_size = 0.2, random_state = 42)

train_df = pd.DataFrame(train)
test_df = pd.DataFrame(test)

train_df.head()

plot_df = train_df.sample(12).reset_index()
plt.figure(figsize=(15, 15))
plot_df.head()

for i in range(12):
    plt.subplot(4,4,i+1)
    plt.imshow(plt.imread(plot_df.loc[i, 'file_name']))
    plt.title((plot_df.loc[i, 'class_name']))
    plt.xticks([])
    plt.yticks([])

train_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15, validation_split = 0.2)
test_datagen=ImageDataGenerator(rescale=1./255.)

train_generator=train_datagen.flow_from_dataframe(
                  dataframe=train_df,
                  directory=None,
                  x_col="file_name",
                  y_col="class_name",
                  subset="training",

                  batch_size=32,
                  seed=42,
                  shuffle=True,
                  class_mode="categorical",
                  target_size=(224, 224))

valid_generator= train_datagen.flow_from_dataframe(
                  dataframe=train_df,
                  directory=None,
                  x_col="file_name",
                  y_col="class_name",
                  subset="validation",
                  batch_size=32,
                  seed=42,
                  shuffle=True,
                  class_mode="categorical",
                  target_size=(224,224))

test_generator=test_datagen.flow_from_dataframe(
                    dataframe=test_df,
                    directory=None,
                    x_col="file_name",
                    y_col="class_name",
                    batch_size=32,
                    seed=42,
                    shuffle=False,
                    class_mode="categorical",
                    target_size=(224,224))

inception_model = InceptionV3(include_top = False,
                       weights = 'imagenet',
                       input_shape = (224,224,3))

for layer in inception_model.layers[:-4]:
    layer.trainable = False

inception_model.summary()


x = GlobalAveragePooling2D()(inception_model.output)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)

outputs = Dense(10, activation='softmax')(x)
model = Model(inputs=inception_model.inputs, outputs=outputs)

model.compile(optimizer=Adam(learning_rate=0.0001),
             loss='categorical_crossentropy',
             metrics=['accuracy'])

model.summary()

checkpoint = ModelCheckpoint( "model.h5",
                            monitor="val_loss",
                            mode="min",
                            save_best_only = True,
                            verbose=1)

earlystopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)
callbacks = [checkpoint,earlystopping]

history = model.fit(train_generator,
                    epochs=5,
                    validation_data=valid_generator,
                    callbacks=callbacks)

#creates a graph with a size of 15 inches wide and 8 inches tall
plt.figure(figsize=(15,8))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss graph')
#This line sets the label for the y-axis of the figure to loss
plt.ylabel('loss')
#This line sets the label for the x-axis of the figure to epoch
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
#This line displays the figure
plt.show()

#creates a graph with a size of 15 inches wide and 8 inches tall
plt.figure(figsize=(15,8))
#This line plots the training accuracy data from the history object on the figure.
plt.plot(history.history['accuracy'])
#This line plots the validation accuracy data from the history object on the figure
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
#This line sets the label for the y-axis of the figure to accuracy
plt.ylabel('accuracy')
#This line sets the label for the x-axis of the figure to epoch
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
#This line displays the figure
plt.show()

